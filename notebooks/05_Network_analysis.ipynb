{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "908238bd-96db-4725-951d-b3c81d66373a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.chdir('/container/mount/point/')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import pickle as pkl\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn import preprocessing\n",
    "from scipy.cluster.hierarchy import linkage, leaves_list\n",
    "\n",
    "from gglasso.problem import glasso_problem\n",
    "from gglasso.helper.basic_linalg import adjacency_matrix\n",
    "from gglasso.helper.basic_linalg import scale_array_by_diagonal\n",
    "\n",
    "from utils.helper import transform_features, scale_array_by_diagonal\n",
    "from utils.preprocessing import add_noise_to_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69bad853-5b8e-4c15-b762-027e2874ff3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_and_save_heatmap(data, title, filename_prefix, height, width, zmid_value=0):\n",
    "    \"\"\"Plot and save heatmap with specified parameters.\"\"\"\n",
    "    heatmap = go.Heatmap(\n",
    "        z=data.values,\n",
    "        x=data.columns,\n",
    "        y=data.index,\n",
    "        colorscale='RdBu_r',\n",
    "        zmid=zmid_value\n",
    "    )\n",
    "\n",
    "    layout = go.Layout(\n",
    "        title=title,\n",
    "        xaxis=dict(tickangle=45, side='top'),\n",
    "        yaxis=dict(autorange='reversed'),\n",
    "        height=height,\n",
    "        width=width\n",
    "    )\n",
    "\n",
    "    fig = go.Figure(data=[heatmap], layout=layout)\n",
    "\n",
    "    for ext in ['png', 'svg', 'pdf']:\n",
    "        fig.write_image(f\"plots/{ext}/{filename_prefix}.{ext}\")\n",
    "    for ext in ['html']:\n",
    "        fig.write_html(f\"plots/{ext}/{filename_prefix}.{ext}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "261bc29d-8e88-480a-a968-8f4eb5d9b2c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "asv = pd.read_csv(\"data/feature_table.tsv\", index_col=0, sep='\\t')\n",
    "control_sample_df = pd.read_csv(\"data/control_samples.csv\", sep=\",\", index_col=0, low_memory=False)\n",
    "cluster_df = pd.read_csv(\"data/cluster_df_latent.csv\", sep=\",\", index_col =0, low_memory=False)\n",
    "covariates = pd.read_csv(\"data/54subset_latent.csv\", sep=\",\", index_col='u3_16s_id', low_memory=False)\n",
    "\n",
    "asv_ige_508_filtered = pd.read_csv(\"data/asv_ige_508.csv\", sep=\",\", index_col=0, low_memory=False)\n",
    "co_occurrence_matrix = pd.read_csv(\"data/co_occurrence_matrix.csv\", sep=\",\", index_col=0, low_memory=False)\n",
    "taxa = pd.read_csv('data/taxonomy_clean.csv', sep=',', index_col=0)\n",
    "taxa[\"ASV\"] = taxa.index\n",
    "\n",
    "# Subset the ASV data to include only columns 508 IgE samples\n",
    "asv_ige_508_all = asv[asv_ige_508_filtered.columns].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97f15ff-b93e-4101-8927-72faf7698aff",
   "metadata": {},
   "source": [
    "### Create datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc3b447-e928-4cb5-b9a0-97c610af4471",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Drop ASVs which are not present in 508 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "962a8ea1-d82c-4898-b1f1-6f6009852a87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clusters = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"I\", \"H\", \"G\"] \n",
    "\n",
    "cluster_asv_data = {}\n",
    "\n",
    "# Loop through each unique cluster\n",
    "for cluster in clusters:\n",
    "    # Get the sample IDs that belong to the current cluster\n",
    "    sample_ids = cluster_df.loc[cluster_df['cluster'] == cluster].index.astype(str)\n",
    "    \n",
    "    # Select the columns in asv_ige_508_all corresponding to these sample IDs\n",
    "    cluster_asv = asv_ige_508_all.loc[:, asv_ige_508_all.columns.isin(sample_ids)]\n",
    "    \n",
    "    # Store the ASV data for the current cluster in the dictionary\n",
    "    cluster_asv_data[cluster] = cluster_asv\n",
    "\n",
    "    \n",
    "healthy_asv = asv_ige_508_all[control_sample_df.index.astype(str)]\n",
    "allergic_asv = asv_ige_508_all.loc[:, ~asv_ige_508_all.columns.isin(control_sample_df.index.astype(str))]\n",
    "\n",
    "cluster_asv_data[\"healthy\"] = healthy_asv\n",
    "cluster_asv_data[\"allergic\"] = allergic_asv\n",
    "cluster_asv_data[\"all\"] = asv_ige_508_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fed5b25-aa47-4574-a27b-43620a2a2a91",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Cluster: A ===\n",
      "ASVs BEFORE dropping zero features: p = 15170\n",
      "ASVs AFTER dropping zero features: p = 758\n",
      "\n",
      "--- Level: phylum ---\n",
      "phylum count table shape: p = 10, N = 12\n",
      "\n",
      "--- Level: class ---\n",
      "class count table shape: p = 15, N = 12\n",
      "\n",
      "--- Level: order ---\n",
      "order count table shape: p = 30, N = 12\n",
      "\n",
      "--- Level: family ---\n",
      "family count table shape: p = 62, N = 12\n",
      "\n",
      "--- Level: genus ---\n",
      "genus count table shape: p = 249, N = 12\n",
      "\n",
      "--- Level: species ---\n",
      "species count table shape: p = 710, N = 12\n",
      "\n",
      "--- Level: ASV ---\n",
      "ASV count table shape: p = 758, N = 12\n",
      "\n",
      "=== Cluster: B ===\n",
      "ASVs BEFORE dropping zero features: p = 15170\n",
      "ASVs AFTER dropping zero features: p = 1276\n",
      "\n",
      "--- Level: phylum ---\n",
      "phylum count table shape: p = 11, N = 24\n",
      "\n",
      "--- Level: class ---\n",
      "class count table shape: p = 17, N = 24\n",
      "\n",
      "--- Level: order ---\n",
      "order count table shape: p = 43, N = 24\n",
      "\n",
      "--- Level: family ---\n",
      "family count table shape: p = 89, N = 24\n",
      "\n",
      "--- Level: genus ---\n",
      "genus count table shape: p = 369, N = 24\n",
      "\n",
      "--- Level: species ---\n",
      "species count table shape: p = 1184, N = 24\n",
      "\n",
      "--- Level: ASV ---\n",
      "ASV count table shape: p = 1276, N = 24\n",
      "\n",
      "=== Cluster: C ===\n",
      "ASVs BEFORE dropping zero features: p = 15170\n",
      "ASVs AFTER dropping zero features: p = 1289\n",
      "\n",
      "--- Level: phylum ---\n",
      "phylum count table shape: p = 11, N = 26\n",
      "\n",
      "--- Level: class ---\n",
      "class count table shape: p = 17, N = 26\n",
      "\n",
      "--- Level: order ---\n",
      "order count table shape: p = 39, N = 26\n",
      "\n",
      "--- Level: family ---\n",
      "family count table shape: p = 77, N = 26\n",
      "\n",
      "--- Level: genus ---\n",
      "genus count table shape: p = 372, N = 26\n",
      "\n",
      "--- Level: species ---\n",
      "species count table shape: p = 1203, N = 26\n",
      "\n",
      "--- Level: ASV ---\n",
      "ASV count table shape: p = 1289, N = 26\n",
      "\n",
      "=== Cluster: D ===\n",
      "ASVs BEFORE dropping zero features: p = 15170\n",
      "ASVs AFTER dropping zero features: p = 1834\n",
      "\n",
      "--- Level: phylum ---\n",
      "phylum count table shape: p = 12, N = 45\n",
      "\n",
      "--- Level: class ---\n",
      "class count table shape: p = 19, N = 45\n",
      "\n",
      "--- Level: order ---\n",
      "order count table shape: p = 49, N = 45\n",
      "\n",
      "--- Level: family ---\n",
      "family count table shape: p = 100, N = 45\n",
      "\n",
      "--- Level: genus ---\n",
      "genus count table shape: p = 456, N = 45\n",
      "\n",
      "--- Level: species ---\n",
      "species count table shape: p = 1697, N = 45\n",
      "\n",
      "--- Level: ASV ---\n",
      "ASV count table shape: p = 1834, N = 45\n",
      "\n",
      "=== Cluster: E ===\n",
      "ASVs BEFORE dropping zero features: p = 15170\n",
      "ASVs AFTER dropping zero features: p = 1107\n",
      "\n",
      "--- Level: phylum ---\n",
      "phylum count table shape: p = 10, N = 22\n",
      "\n",
      "--- Level: class ---\n",
      "class count table shape: p = 16, N = 22\n",
      "\n",
      "--- Level: order ---\n",
      "order count table shape: p = 38, N = 22\n",
      "\n",
      "--- Level: family ---\n",
      "family count table shape: p = 75, N = 22\n",
      "\n",
      "--- Level: genus ---\n",
      "genus count table shape: p = 320, N = 22\n",
      "\n",
      "--- Level: species ---\n",
      "species count table shape: p = 1037, N = 22\n",
      "\n",
      "--- Level: ASV ---\n",
      "ASV count table shape: p = 1107, N = 22\n",
      "\n",
      "=== Cluster: F ===\n",
      "ASVs BEFORE dropping zero features: p = 15170\n",
      "ASVs AFTER dropping zero features: p = 507\n",
      "\n",
      "--- Level: phylum ---\n",
      "phylum count table shape: p = 7, N = 10\n",
      "\n",
      "--- Level: class ---\n",
      "class count table shape: p = 12, N = 10\n",
      "\n",
      "--- Level: order ---\n",
      "order count table shape: p = 27, N = 10\n",
      "\n",
      "--- Level: family ---\n",
      "family count table shape: p = 52, N = 10\n",
      "\n",
      "--- Level: genus ---\n",
      "genus count table shape: p = 181, N = 10\n",
      "\n",
      "--- Level: species ---\n",
      "species count table shape: p = 482, N = 10\n",
      "\n",
      "--- Level: ASV ---\n",
      "ASV count table shape: p = 507, N = 10\n",
      "\n",
      "=== Cluster: I ===\n",
      "ASVs BEFORE dropping zero features: p = 15170\n",
      "ASVs AFTER dropping zero features: p = 2420\n",
      "\n",
      "--- Level: phylum ---\n",
      "phylum count table shape: p = 11, N = 74\n",
      "\n",
      "--- Level: class ---\n",
      "class count table shape: p = 18, N = 74\n",
      "\n",
      "--- Level: order ---\n",
      "order count table shape: p = 52, N = 74\n",
      "\n",
      "--- Level: family ---\n",
      "family count table shape: p = 110, N = 74\n",
      "\n",
      "--- Level: genus ---\n",
      "genus count table shape: p = 580, N = 74\n",
      "\n",
      "--- Level: species ---\n",
      "species count table shape: p = 2226, N = 74\n",
      "\n",
      "--- Level: ASV ---\n",
      "ASV count table shape: p = 2420, N = 74\n",
      "\n",
      "=== Cluster: H ===\n",
      "ASVs BEFORE dropping zero features: p = 15170\n",
      "ASVs AFTER dropping zero features: p = 1709\n",
      "\n",
      "--- Level: phylum ---\n",
      "phylum count table shape: p = 12, N = 40\n",
      "\n",
      "--- Level: class ---\n",
      "class count table shape: p = 17, N = 40\n",
      "\n",
      "--- Level: order ---\n",
      "order count table shape: p = 48, N = 40\n",
      "\n",
      "--- Level: family ---\n",
      "family count table shape: p = 91, N = 40\n",
      "\n",
      "--- Level: genus ---\n",
      "genus count table shape: p = 452, N = 40\n",
      "\n",
      "--- Level: species ---\n",
      "species count table shape: p = 1587, N = 40\n",
      "\n",
      "--- Level: ASV ---\n",
      "ASV count table shape: p = 1709, N = 40\n",
      "\n",
      "=== Cluster: G ===\n",
      "ASVs BEFORE dropping zero features: p = 15170\n",
      "ASVs AFTER dropping zero features: p = 1162\n",
      "\n",
      "--- Level: phylum ---\n",
      "phylum count table shape: p = 8, N = 22\n",
      "\n",
      "--- Level: class ---\n",
      "class count table shape: p = 14, N = 22\n",
      "\n",
      "--- Level: order ---\n",
      "order count table shape: p = 35, N = 22\n",
      "\n",
      "--- Level: family ---\n",
      "family count table shape: p = 72, N = 22\n",
      "\n",
      "--- Level: genus ---\n",
      "genus count table shape: p = 309, N = 22\n",
      "\n",
      "--- Level: species ---\n",
      "species count table shape: p = 1077, N = 22\n",
      "\n",
      "--- Level: ASV ---\n",
      "ASV count table shape: p = 1162, N = 22\n",
      "\n",
      "=== Cluster: healthy ===\n",
      "ASVs BEFORE dropping zero features: p = 15170\n",
      "ASVs AFTER dropping zero features: p = 4678\n",
      "\n",
      "--- Level: phylum ---\n",
      "phylum count table shape: p = 12, N = 233\n",
      "\n",
      "--- Level: class ---\n",
      "class count table shape: p = 19, N = 233\n",
      "\n",
      "--- Level: order ---\n",
      "order count table shape: p = 48, N = 233\n",
      "\n",
      "--- Level: family ---\n",
      "family count table shape: p = 91, N = 233\n",
      "\n",
      "--- Level: genus ---\n",
      "genus count table shape: p = 437, N = 233\n",
      "\n",
      "--- Level: species ---\n",
      "species count table shape: p = 1440, N = 233\n",
      "\n",
      "--- Level: ASV ---\n",
      "ASV count table shape: p = 1538, N = 233\n",
      "\n",
      "=== Cluster: allergic ===\n",
      "ASVs BEFORE dropping zero features: p = 15170\n",
      "ASVs AFTER dropping zero features: p = 4929\n",
      "\n",
      "--- Level: phylum ---\n",
      "phylum count table shape: p = 12, N = 275\n",
      "\n",
      "--- Level: class ---\n",
      "class count table shape: p = 18, N = 275\n",
      "\n",
      "--- Level: order ---\n",
      "order count table shape: p = 47, N = 275\n",
      "\n",
      "--- Level: family ---\n",
      "family count table shape: p = 93, N = 275\n",
      "\n",
      "--- Level: genus ---\n",
      "genus count table shape: p = 431, N = 275\n",
      "\n",
      "--- Level: species ---\n",
      "species count table shape: p = 1492, N = 275\n",
      "\n",
      "--- Level: ASV ---\n",
      "ASV count table shape: p = 1592, N = 275\n",
      "\n",
      "=== Cluster: all ===\n",
      "ASVs BEFORE dropping zero features: p = 15170\n",
      "ASVs AFTER dropping zero features: p = 6958\n",
      "\n",
      "--- Level: phylum ---\n",
      "phylum count table shape: p = 12, N = 508\n",
      "\n",
      "--- Level: class ---\n",
      "class count table shape: p = 18, N = 508\n",
      "\n",
      "--- Level: order ---\n",
      "order count table shape: p = 47, N = 508\n",
      "\n",
      "--- Level: family ---\n",
      "family count table shape: p = 91, N = 508\n",
      "\n",
      "--- Level: genus ---\n",
      "genus count table shape: p = 402, N = 508\n",
      "\n",
      "--- Level: species ---\n",
      "species count table shape: p = 1329, N = 508\n",
      "\n",
      "--- Level: ASV ---\n",
      "ASV count table shape: p = 1422, N = 508\n"
     ]
    }
   ],
   "source": [
    "levels = [\"phylum\", \"class\", \"order\", \"family\", \"genus\", \"species\", \"ASV\"]\n",
    "\n",
    "data_dict = dict()\n",
    "threshold = 0.01\n",
    "\n",
    "for cluster, asv_table in cluster_asv_data.items():\n",
    "    print(f\"\\n=== Cluster: {cluster} ===\")\n",
    "\n",
    "    ASV_table = asv_table.copy()\n",
    "    # Initialize dictionary for the current cluster\n",
    "    if cluster not in data_dict:\n",
    "        data_dict[cluster] = {}\n",
    "\n",
    "    #################### DROP ZERO FEATURES ##############################\n",
    "    print(f\"ASVs BEFORE dropping zero features: p = {ASV_table.shape[0]}\")\n",
    "\n",
    "    ### Frequency of bacterium across all samples\n",
    "    taxa_freq = ASV_table.sum(axis=1)\n",
    "\n",
    "    ### drop features with NO COUNTS\n",
    "    non_zero_taxa = taxa_freq[taxa_freq > 0]\n",
    "\n",
    "    ### Filter ASV table based on non-zero frequencies\n",
    "    ASV_table_non_zero = ASV_table[ASV_table.index.isin(non_zero_taxa.index)]\n",
    "\n",
    "    ### Filter columns with zero mean\n",
    "    asv_samples_ids = set(ASV_table_non_zero.columns)\n",
    "    means = ASV_table_non_zero.mean()\n",
    "    zero_mean_cols = means[means == 0].index\n",
    "\n",
    "    ### Drop columns with zero mean if any\n",
    "    if any(zero_mean_cols):\n",
    "        print(f\"Zero mean features found and removed: {list(zero_mean_cols)}\")\n",
    "        ASV_table_non_zero = ASV_table_non_zero.drop(zero_mean_cols, axis=1)\n",
    "\n",
    "    print(f\"ASVs AFTER dropping zero features: p = {ASV_table_non_zero.shape[0]}\")\n",
    "\n",
    "    for level in levels:\n",
    "        print(f\"\\n--- Level: {level} ---\")\n",
    "\n",
    "        ##################### AGGREGATION ##############################\n",
    "        counts_plus_label = ASV_table_non_zero.join(taxa[level])\n",
    "        counts = counts_plus_label.groupby(level).sum()\n",
    "\n",
    "        ### DO THE FILTERING ON EVERY LEVEL\n",
    "        counts_freq = counts.astype(bool).sum(axis=1) / counts.shape[1]\n",
    "        filter_threshold = counts_freq[counts_freq > threshold]\n",
    "        counts_filtered = counts[counts.index.isin(filter_threshold.index)]\n",
    "\n",
    "        ### Apply CLR transformation\n",
    "        clr_counts = transform_features(counts_filtered, transformation='clr')\n",
    "        mclr_counts = transform_features(counts_filtered, transformation='mclr')\n",
    "        \n",
    "        ### Calculate covariance\n",
    "        S0 = np.cov(clr_counts.values, bias = True)\n",
    "        S = scale_array_by_diagonal(S0)\n",
    "        corr_df = pd.DataFrame(S, index=clr_counts.index, columns=clr_counts.index)\n",
    "\n",
    "        data_dict[cluster][level] = {'raw_counts': counts_filtered, \n",
    "                                     'clr_counts': clr_counts, \n",
    "                                     'mclr_counts': mclr_counts,\n",
    "                                     \"corr\": corr_df}\n",
    "\n",
    "        print(f\"{level} count table shape: p = {counts_filtered.shape[0]}, N = {counts_filtered.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a17db605-d2bf-4fe2-a219-0ec7a6847968",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# with open('data/cluster_count_dict.pkl', 'wb') as f:\n",
    "#     pkl.dump(data_dict, f)\n",
    "    \n",
    "with open('data/cluster_count_dict.pkl', 'rb') as f:\n",
    "    data_dict = pkl.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa52841-9d13-4837-b6ee-a0b942f92fb3",
   "metadata": {},
   "source": [
    "### Load solutions without IgE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea49ffac-c2be-4816-a1c5-b499099d608c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('data/inv_corr_dict_only_taxa_all.pkl', 'rb') as f:\n",
    "    sol_dict_taxa = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b41c7938-c6cf-4509-b55d-b250bce41e53",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "B\n",
      "C\n",
      "D\n",
      "E\n",
      "F\n",
      "I\n",
      "\n",
      " I\n",
      "Best lambda: 0.6951927961775606\n",
      "Cluster: I, level:family\n",
      "Count Shape: (110, 110)\n",
      "H\n",
      "G\n",
      "healthy\n",
      "\n",
      " healthy\n",
      "Best lambda: 0.23357214690901223\n",
      "Cluster: healthy, level:family\n",
      "Count Shape: (91, 91)\n",
      "allergic\n",
      "\n",
      " allergic\n",
      "Best lambda: 0.23357214690901223\n",
      "Cluster: allergic, level:family\n",
      "Count Shape: (93, 93)\n",
      "all\n",
      "\n",
      " all\n",
      "Best lambda: 0.23357214690901223\n",
      "Cluster: all, level:family\n",
      "Count Shape: (91, 91)\n"
     ]
    }
   ],
   "source": [
    "stacked_sol_dict = dict()\n",
    "level = 'family'\n",
    "\n",
    "for cluster in data_dict.keys():\n",
    "    print(cluster)\n",
    "    best_lam = sol_dict_taxa[cluster][level]['model_stats']['BEST'][\"lambda1\"]\n",
    "    \n",
    "    if best_lam != 1 and best_lam != 0:\n",
    "        print(\"\\n\", cluster)\n",
    "        print(\"Best lambda:\", best_lam)\n",
    "        \n",
    "        X = data_dict[cluster][level]['raw_counts']\n",
    "        df = sol_dict_taxa[cluster][level]['inv_corr']\n",
    "        \n",
    "        #### Cluster the edges #### \n",
    "        count_block = df.loc[X.index, X.index]\n",
    "        \n",
    "        print(\"Cluster: {0}, level:{1}\".format(cluster, level))\n",
    "        print(\"Count Shape: {0}\".format(count_block.shape))\n",
    "\n",
    "        linkage_count_block = linkage(count_block, method='average')\n",
    "        ordered_indices_count_block = leaves_list(linkage_count_block)\n",
    "        res_df = count_block.iloc[ordered_indices_count_block, ordered_indices_count_block]\n",
    "            \n",
    "        df.index.name = None\n",
    "\n",
    "        # Reset the index to turn the index into a column\n",
    "        df_reset = df.reset_index()\n",
    "\n",
    "#         # Melt the DataFrame to create a stacked format\n",
    "        stacked_df = df_reset.melt(id_vars='index', var_name='Y', value_name='inv_corr')\n",
    "\n",
    "        # Rename the 'index' column to 'X'\n",
    "        stacked_df.rename(columns={'index': 'X'}, inplace=True)\n",
    "\n",
    "        # Optionally drop NaN values if you don't want them in the final DataFrame\n",
    "        stacked_df.dropna(subset=['inv_corr'], inplace=True)\n",
    "\n",
    "        # Store the stacked DataFrame in the dictionary\n",
    "        stacked_sol_dict[cluster] = stacked_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96d6410b-a354-41ef-9b3a-02c3faf06b21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_stacked_df = pd.concat(stacked_sol_dict.values(), ignore_index=True)\n",
    "\n",
    "# remove duplicate edges by keeping the biggest ones\n",
    "all_stacked_df = all_stacked_df.loc[all_stacked_df.groupby(['X', 'Y'])['inv_corr'].apply(lambda x: x.abs().idxmax())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52281ca7-79c5-43d5-8c82-d97a8f5b95e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "symmetric_df = all_stacked_df.pivot(index='X', columns='Y', values='inv_corr')\n",
    "symmetric_df = symmetric_df.fillna(0)\n",
    "A = symmetric_df.copy()\n",
    "\n",
    "A.to_csv('data/super_matrix_only_taxa_main.csv', index=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17203498-dae3-47c6-81ef-d82a74e96123",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for cluster in stacked_sol_dict.keys():\n",
    "    \n",
    "    C = A.copy()\n",
    "    B = stacked_sol_dict[cluster].pivot(index='X', columns='Y', values='inv_corr').copy()\n",
    "    \n",
    "    cols_to_zero = C.columns[~C.columns.isin(B.columns)]\n",
    "    index_to_zero = C.index[~C.index.isin(B.index)]\n",
    "\n",
    "    # Set values to 0 in A for those columns and indices\n",
    "    C[cols_to_zero] = 0\n",
    "    C.loc[index_to_zero] = 0\n",
    "\n",
    "    for index in C.index:\n",
    "        if index in C.columns:\n",
    "            C.at[index, index] = 1\n",
    "                \n",
    "    C.to_csv(f'data/super_matrix_only_taxa_{cluster}.csv', index=True, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6e8355-faef-4204-83ca-b7e24765fab7",
   "metadata": {},
   "source": [
    "#### Heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95562761-a178-4bc8-9282-184f7fdc0421",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "count_block = A.loc[A.index[A.index.str.startswith('f__')], \n",
    "                    A.index[A.index.str.startswith('f__')]]\n",
    "\n",
    "linkage_count_block = linkage(count_block, method='average')\n",
    "ordered_indices_count_block = leaves_list(linkage_count_block)\n",
    "main_df = count_block.iloc[ordered_indices_count_block, \n",
    "                                  ordered_indices_count_block]\n",
    "main_labels = main_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "351c1f53-995c-440b-af4d-1422d12abfd7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of edges: 19\n"
     ]
    }
   ],
   "source": [
    "healthy = pd.read_csv(\"data/super_matrix_only_taxa_healthy.csv\", sep=\",\", index_col=0, low_memory=False)\n",
    "allergic = pd.read_csv(\"data/super_matrix_only_taxa_allergic.csv\", sep=\",\", index_col=0, low_memory=False)\n",
    "\n",
    "# Reorder columns and indices\n",
    "healthy = healthy.reindex(index=main_labels, columns=main_labels)\n",
    "allergic = allergic.reindex(index=main_labels, columns=main_labels)\n",
    "\n",
    "# Compute difference\n",
    "diff_counts = healthy - allergic\n",
    "# plot_and_save_heatmap(diff_counts, 'Difference: healthy - allergic', f'rel_diff_heatmap_only_taxa_{level}')\n",
    "\n",
    "# Binary difference heatmap\n",
    "binary_diff_counts = diff_counts.astype(bool).astype(int)\n",
    "# plot_and_save_heatmap(data=binary_diff_counts, 'Binary Difference: healthy - allergic', f'bin_diff_heatmap_only_taxa_{level}')\n",
    "\n",
    "abs_diff_counts = healthy.astype(bool).astype(int) - allergic.astype(bool).astype(int)\n",
    "# plot_and_save_heatmap(abs_diff_counts, 'Absolute Difference: healthy - allergic', f'abs_diff_heatmap_only_taxa_{level}')\n",
    "\n",
    "nonzero_edges = np.triu(abs_diff_counts.astype(bool).astype(int), k=1).sum()\n",
    "print(f\"Number of edges: {nonzero_edges}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fdd5a0bd-0414-4d86-96d3-7f733e309dbe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "diff_counts.to_csv(f'data/diff_only_taxa_matrix.csv', index=True, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c79db07-913a-4487-bd09-da14141ef551",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load solutions with IgE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "608b6730-9927-4762-b064-a7035688a41f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('data/inv_corr_dict_all.pkl', 'rb') as f:\n",
    "    sol_dict = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a146bf2-0efb-46a9-84f1-5992b7905a1e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "B\n",
      "C\n",
      "D\n",
      "E\n",
      "F\n",
      "I\n",
      "\n",
      " I\n",
      "Best lambda: 0.4832930238571754\n",
      "Cluster: I, level:family\n",
      "Count Shape: (110, 110)\n",
      "IgE Shape: (51, 51)\n",
      "H\n",
      "\n",
      " H\n",
      "Best lambda: 0.6951927961775606\n",
      "Cluster: H, level:family\n",
      "Count Shape: (91, 91)\n",
      "IgE Shape: (48, 48)\n",
      "G\n",
      "healthy\n",
      "\n",
      " healthy\n",
      "Best lambda: 0.23357214690901223\n",
      "Cluster: healthy, level:family\n",
      "Count Shape: (91, 91)\n",
      "IgE Shape: (0, 0)\n",
      "allergic\n",
      "\n",
      " allergic\n",
      "Best lambda: 0.16237767391887217\n",
      "Cluster: allergic, level:family\n",
      "Count Shape: (93, 93)\n",
      "IgE Shape: (104, 104)\n",
      "all\n",
      "\n",
      " all\n",
      "Best lambda: 0.11288378916846892\n",
      "Cluster: all, level:family\n",
      "Count Shape: (91, 91)\n",
      "IgE Shape: (104, 104)\n"
     ]
    }
   ],
   "source": [
    "stacked_sol_dict = dict()\n",
    "level = 'family'\n",
    "\n",
    "for cluster in data_dict.keys():\n",
    "    print(cluster)\n",
    "    best_lam = sol_dict[cluster][level]['model_stats']['BEST'][\"lambda1\"]\n",
    "    \n",
    "    if best_lam != 1 and best_lam != 0:\n",
    "        print(\"\\n\", cluster)\n",
    "        print(\"Best lambda:\", best_lam)\n",
    "        \n",
    "        X = data_dict[cluster][level]['raw_counts']\n",
    "        df = sol_dict[cluster][level]['inv_corr']\n",
    "        \n",
    "        #### Cluster the edges #### \n",
    "        count_block = df.loc[X.index, X.index]\n",
    "        ige_block = df.loc[~df.index.isin(X.index), ~df.columns.isin(X.index)]\n",
    "        count_ige_block = df.loc[X.index, ~df.columns.isin(X.index)]\n",
    "        \n",
    "        print(\"Cluster: {0}, level:{1}\".format(cluster, level))\n",
    "        print(\"Count Shape: {0}\".format(count_block.shape))\n",
    "        print(\"IgE Shape: {0}\".format(ige_block.shape))\n",
    "\n",
    "        linkage_count_block = linkage(count_block, method='average')\n",
    "        ordered_indices_count_block = leaves_list(linkage_count_block)\n",
    "        re_count_block = count_block.iloc[ordered_indices_count_block, ordered_indices_count_block]\n",
    "        \n",
    "        \n",
    "        if cluster != \"healthy\":\n",
    "            linkage_ige_block = linkage(ige_block, method='average')\n",
    "            ordered_indices_ige_block = leaves_list(linkage_ige_block)\n",
    "            re_ige_block = ige_block.iloc[ordered_indices_ige_block, ordered_indices_ige_block]\n",
    "\n",
    "            re_count_ige_block = count_ige_block.iloc[ordered_indices_count_block, ordered_indices_ige_block]\n",
    "\n",
    "            res = np.block([[re_count_block.values, re_count_ige_block.values],\n",
    "                                [re_count_ige_block.T.values, re_ige_block.values]])\n",
    "\n",
    "            labels = list(re_count_block.columns) + list(re_ige_block.columns)\n",
    "            res_df = pd.DataFrame(res, index=labels, columns=labels)\n",
    "            \n",
    "        else:\n",
    "            res_df = re_count_block.copy()\n",
    "            \n",
    "        \n",
    "        #### Plot the solutions #### \n",
    "#         fig = px.imshow(-20*res_df, \n",
    "#                     color_continuous_scale='RdBu_r',  # Adjust the color scale\n",
    "#                     labels={'color': 'Value'},          # Label for color bar\n",
    "#                     title=f'Heatmap of {level} binary filtered data ({cluster})',\n",
    "#                     zmin=-1, zmax=1, color_continuous_midpoint=0)\n",
    "\n",
    "#         # Customize layout for better visuals (optional)\n",
    "#         fig.update_layout(\n",
    "#             width=1200,  # Adjust width\n",
    "#             height=1200 # Adjust height\n",
    "#         )\n",
    "\n",
    "#         # # Show the plot\n",
    "#         fig.show()\n",
    "            \n",
    "        df.index.name = None\n",
    "\n",
    "        # Reset the index to turn the index into a column\n",
    "        df_reset = df.reset_index()\n",
    "\n",
    "#         # Melt the DataFrame to create a stacked format\n",
    "        stacked_df = df_reset.melt(id_vars='index', var_name='Y', value_name='inv_corr')\n",
    "\n",
    "        # Rename the 'index' column to 'X'\n",
    "        stacked_df.rename(columns={'index': 'X'}, inplace=True)\n",
    "\n",
    "        # Optionally drop NaN values if you don't want them in the final DataFrame\n",
    "        stacked_df.dropna(subset=['inv_corr'], inplace=True)\n",
    "\n",
    "        # Store the stacked DataFrame in the dictionary\n",
    "        stacked_sol_dict[cluster] = stacked_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8468ccd-01bb-46f7-a488-c65efedd6a96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_stacked_df = pd.concat(stacked_sol_dict.values(), ignore_index=True)\n",
    "\n",
    "# remove duplicate edges by keeping the biggest ones\n",
    "all_stacked_df = all_stacked_df.loc[all_stacked_df.groupby(['X', 'Y'])['inv_corr'].apply(lambda x: x.abs().idxmax())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "43a772bf-9393-46d6-8067-bccd4e5ae2dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "symmetric_df = all_stacked_df.pivot(index='X', columns='Y', values='inv_corr')\n",
    "symmetric_df = symmetric_df.fillna(0)\n",
    "A = symmetric_df.copy()\n",
    "\n",
    "A.to_csv('data/super_matrix_main.csv', index=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e8721293-6618-4ffe-98b0-45e54970ec8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for cluster in stacked_sol_dict.keys():\n",
    "    \n",
    "    C = A.copy()\n",
    "    B = stacked_sol_dict[cluster].pivot(index='X', columns='Y', values='inv_corr').copy()\n",
    "    \n",
    "    cols_to_zero = C.columns[~C.columns.isin(B.columns)]\n",
    "    index_to_zero = C.index[~C.index.isin(B.index)]\n",
    "\n",
    "    # Set values to 0 in A for those columns and indices\n",
    "    C[cols_to_zero] = 0\n",
    "    C.loc[index_to_zero] = 0\n",
    "\n",
    "    for index in C.index:\n",
    "        if index in C.columns:\n",
    "            C.at[index, index] = 1\n",
    "                \n",
    "    C.to_csv(f'data/super_matrix_{cluster}.csv', index=True, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a108fe3-8fb8-40da-ad6b-812b15836c7b",
   "metadata": {},
   "source": [
    "#### Heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "286dd41a-f8d6-4e6b-8dcd-c7c62aa958ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "count_block = A.loc[A.index[A.index.str.startswith('f__')], \n",
    "                    A.index[A.index.str.startswith('f__')]]\n",
    "\n",
    "linkage_count_block = linkage(count_block, method='average')\n",
    "ordered_indices_count_block = leaves_list(linkage_count_block)\n",
    "re_count_block = count_block.iloc[ordered_indices_count_block, \n",
    "                                  ordered_indices_count_block]\n",
    "\n",
    "# Extract ige_block using co-occurrence IgE order\n",
    "ige_block = A.loc[A.index[A.index.isin(co_occurrence_matrix.columns)], \n",
    "                  A.index[A.index.isin(co_occurrence_matrix.columns)]]\n",
    "\n",
    "# Extract count_ige_block\n",
    "count_ige_block = A.loc[count_block.index, ige_block.index]\n",
    "\n",
    "# Ensure count_ige_block rows are reordered like count_block\n",
    "re_count_ige_block = count_ige_block.iloc[ordered_indices_count_block, :]\n",
    "\n",
    "# Combine index and columns for the final DataFrame\n",
    "main_labels = list(re_count_block.index) + list(ige_block.index)\n",
    "\n",
    "main_df = pd.DataFrame(\n",
    "    np.block([\n",
    "        [re_count_block.values, re_count_ige_block.values],\n",
    "        [re_count_ige_block.T.values, ige_block.values]\n",
    "    ]),\n",
    "    index=main_labels,\n",
    "    columns=main_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6d2286d8-817f-44f5-a773-ddb159211efd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of edges: 85\n"
     ]
    }
   ],
   "source": [
    "healthy = pd.read_csv(\"data/super_matrix_healthy.csv\", sep=\",\", index_col=0, low_memory=False)\n",
    "allergic = pd.read_csv(\"data/super_matrix_allergic.csv\", sep=\",\", index_col=0, low_memory=False)\n",
    "\n",
    "# Reorder columns and indices\n",
    "healthy = healthy.reindex(index=main_labels, columns=main_labels)\n",
    "allergic = allergic.reindex(index=main_labels, columns=main_labels)\n",
    "\n",
    "# Extract count blocks\n",
    "healthy_count_block = healthy.iloc[:-104, :-104]\n",
    "allergic_count_block = allergic.iloc[:-104, :-104]\n",
    "\n",
    "### Sort by connections between taxa and IgEs\n",
    "allergic_ige = allergic.iloc[:-104, -104:].astype(bool).astype(int)\n",
    "connections_order = allergic_ige.astype(bool).astype(int).sum(axis=1).sort_values(ascending=False)\n",
    "\n",
    "allergic_ige_filtered = allergic_ige.loc[:, (allergic_ige != 0).any(axis=0)]\n",
    "# Perform hierarchical clustering\n",
    "linkage_ige = linkage(allergic_ige_filtered.T, method='average')\n",
    "column_order = leaves_list(linkage_ige)\n",
    "# Reindex columns to match the clustering order\n",
    "allergic_ige_clustered = allergic_ige_filtered.iloc[:, column_order]\n",
    "\n",
    "healthy_count_block = healthy_count_block.reindex(index=connections_order.index, columns=connections_order.index)\n",
    "allergic_count_block = allergic_count_block.reindex(index=connections_order.index, columns=connections_order.index)\n",
    "\n",
    "# Compute difference\n",
    "diff_counts = healthy_count_block - allergic_count_block\n",
    "plot_and_save_heatmap(diff_counts, 'Difference: healthy - allergic', f'rel_diff_heatmap_{level}',\n",
    "                     height=2500, width=2500)\n",
    "\n",
    "# Binary difference heatmap\n",
    "binary_diff_counts = diff_counts.astype(bool).astype(int)\n",
    "binary_diff_counts_ige = binary_diff_counts.join(allergic_ige_clustered)\n",
    "plot_and_save_heatmap(data=binary_diff_counts_ige, title='Binary Difference: healthy - allergic', filename_prefix=f'bin_diff_heatmap_{level}',\n",
    "                     height=2500, width=4000)\n",
    "\n",
    "# Absolute difference heatmap\n",
    "abs_diff_counts = healthy_count_block.astype(bool).astype(int) - allergic_count_block.astype(bool).astype(int)\n",
    "abs_diff_counts_ige = abs_diff_counts.join(allergic_ige_clustered)\n",
    "plot_and_save_heatmap(abs_diff_counts_ige, 'Absolute Difference: healthy - allergic', f'abs_diff_heatmap_{level}',\n",
    "                     height=2500, width=4000)\n",
    "\n",
    "abs_diff_counts_non_empty = abs_diff_counts.loc[\n",
    "    (abs_diff_counts != 0).any(axis=1),  # Drop empty rows\n",
    "    (abs_diff_counts != 0).any(axis=0)   # Drop empty columns\n",
    "]\n",
    "abs_diff_counts_non_empty = abs_diff_counts_non_empty.join(allergic_ige_clustered)\n",
    "plot_and_save_heatmap(abs_diff_counts_non_empty, 'Absolute Difference (filtered): healthy - allergic', f'abs_diff_heatmap_{level}_filtered',\n",
    "                     height=1500, width=2500)\n",
    "\n",
    "nonzero_edges = np.triu(abs_diff_counts.astype(bool).astype(int), k=1).sum()\n",
    "print(f\"Number of edges: {nonzero_edges}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763d7dbe-2003-4add-9336-0b96e5875a88",
   "metadata": {},
   "source": [
    "### Compare solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1ad2dffc-2499-4dc8-9e04-26db693344cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### only counts\n",
    "main_df = pd.read_csv(\"data/super_matrix_only_taxa_main.csv\", sep=\",\", index_col=0, low_memory=False)\n",
    "healthy = pd.read_csv(\"data/super_matrix_only_taxa_healthy.csv\", sep=\",\", index_col=0, low_memory=False)\n",
    "allergic = pd.read_csv(\"data/super_matrix_only_taxa_allergic.csv\", sep=\",\", index_col=0, low_memory=False)\n",
    "\n",
    "### counts + IgEs\n",
    "main_df_ige = pd.read_csv(\"data/super_matrix_main.csv\", sep=\",\", index_col=0, low_memory=False)\n",
    "healthy_ige = pd.read_csv(\"data/super_matrix_healthy.csv\", sep=\",\", index_col=0, low_memory=False)\n",
    "allergic_ige = pd.read_csv(\"data/super_matrix_allergic.csv\", sep=\",\", index_col=0, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "830a5d52-7f88-4b44-8bdd-831f69f1a216",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Calculate the difference\n",
    "healthy_count_block = healthy_ige.filter(regex=\"^f__\", axis=0).filter(regex=\"^f__\", axis=1)\n",
    "allergic_count_block = allergic_ige.filter(regex=\"^f__\", axis=0).filter(regex=\"^f__\", axis=1)\n",
    "### we compare presence/absence -> .astype(bool).astype(int)\n",
    "diff_ige_counts = healthy_count_block.astype(bool).astype(int) - allergic_count_block.astype(bool).astype(int)\n",
    "\n",
    "diff_ige = healthy_ige.copy()\n",
    "diff_ige.update(diff_ige_counts)\n",
    "\n",
    "diff_ige.to_csv(f'data/diff_matrix.csv', index=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b0fdb05d-ac90-4f12-b4aa-b3f5065fdaba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['f__Eubacteriaceae;',\n",
       " 'f__Saccharimonadaceae;',\n",
       " 'f__unknown_15;',\n",
       " 'f__unknown_27;']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_ige.loc['f__Veillonellaceae;'][diff_ige.loc['f__Veillonellaceae;'] != 0].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9d13b4ba-0aa4-4108-8d1a-baf09884e028",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "diff_counts = pd.read_csv(\"data/diff_only_taxa_matrix.csv\", sep=\",\", index_col=0, low_memory=False)\n",
    "diff_ige = pd.read_csv(\"data/diff_matrix.csv\", sep=\",\", index_col=0, low_memory=False)\n",
    "\n",
    "# Filter columns in diff_counts that are not full of zeros \n",
    "filtered_diff_counts = diff_counts.loc[\n",
    "    (diff_counts != 0).any(axis=1),  \n",
    "    (diff_counts != 0).any(axis=0)]\n",
    "\n",
    "# Filter columns in diff_ige that are not full of zeros and start with \"f__\"\n",
    "filtered_diff_ige = diff_ige.loc[\n",
    "    (diff_ige != 0).any(axis=1) & diff_ige.columns.str.startswith(\"f__\"),  \n",
    "    (diff_ige != 0).any(axis=0) & diff_ige.columns.str.startswith(\"f__\")]\n",
    "\n",
    "filtered_diff_counts = filtered_diff_counts.reindex(index=filtered_diff_ige.index, \n",
    "                                                    columns=filtered_diff_ige.columns, fill_value=0)\n",
    "\n",
    "filtered_diff_counts.to_csv(f'data/diff_matrix_filtered.csv', index=True, header=True)\n",
    "filtered_diff_ige.to_csv(f'data/diff_matrix_filtered_ige.csv', index=True, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7a4e98-73ef-46ce-9e58-ece987b641cc",
   "metadata": {},
   "source": [
    "### Prepare data for NetComi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ac88098c-78cd-4a83-8073-545615d7bdeb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IgE Shape: (508, 104)\n",
      "No columns contain only zeros.\n"
     ]
    }
   ],
   "source": [
    "ige_data = pd.read_csv(\"data/ige_kora_subset_all.csv\", sep=\",\", index_col =\"u3_16s_id\", low_memory=False)\n",
    "print(\"IgE Shape:\", ige_data.shape)\n",
    "\n",
    "# Check for columns with only zeros\n",
    "zero_columns = ige_data.columns[(ige_data == 0).all()]\n",
    "\n",
    "# Print the columns with only zeros and their count\n",
    "if not zero_columns.empty:\n",
    "    print(f\"Columns with only zeros: {list(zero_columns)}\")\n",
    "    print(f\"Dropped Number of columns with only zeros: {len(zero_columns)}\")\n",
    "    ige_data = ige_data.drop(columns=zero_columns)\n",
    "    ige_data = ige_data.astype(bool).astype(int)\n",
    "    ige_data.index = ige_data.index.astype(str)\n",
    "\n",
    "else:\n",
    "    print(\"No columns contain only zeros.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8c11b607-e982-4738-b3ec-dad2d7f3fa25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataframes = []\n",
    "\n",
    "# Iterate over each cluster in data_dict\n",
    "for cluster in stacked_sol_dict.keys():\n",
    "    # Extract the 'raw_counts' DataFrame for the 'family' level of each cluster\n",
    "    df = data_dict[cluster]['family']['raw_counts']\n",
    "    dataframes.append(df)\n",
    "\n",
    "# Concatenate all DataFrames by columns\n",
    "merged_df = pd.concat(dataframes)\n",
    "merged_df = merged_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3ca720c2-6d1a-4b7c-a0fa-f35576c33efe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Does the index have duplicates? True\n",
      "Does the index have duplicates after? False\n"
     ]
    }
   ],
   "source": [
    "df = merged_df.copy()\n",
    "\n",
    "has_duplicates = df.index.duplicated().any()\n",
    "\n",
    "print(f\"Does the index have duplicates? {has_duplicates}\")\n",
    "\n",
    "### drop duplicates\n",
    "df['non_zero_count'] = (df != 0).sum(axis=1) # Create a helper column that counts the number of non-zero values per row\n",
    "df_sorted = df.sort_values(by='non_zero_count', ascending=False) # Sort the DataFrame by the non-zero count in descending order\n",
    "df_unique = df_sorted[~df_sorted.index.duplicated(keep='first')] # Drop duplicates based on the index, keeping the row with the highest non-zero count\n",
    "df_unique = df_unique.drop(columns='non_zero_count') # Drop the helper column as it's no longer needed\n",
    "\n",
    "has_duplicates = df_unique.index.duplicated().any()\n",
    "\n",
    "print(f\"Does the index have duplicates after? {has_duplicates}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4161308f-5942-4d79-a1d1-40603120e337",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Transform the data\n",
    "mclr_counts_family = transform_features(df_unique, transformation='mclr')\n",
    "\n",
    "# Transpose ige_data\n",
    "ige_T = ige_data.T\n",
    "\n",
    "# Ensure column types are strings for alignment\n",
    "ige_T.columns = ige_T.columns.astype(str)\n",
    "\n",
    "# Reorder ige_T to match mclr_counts_family column order\n",
    "ige_T = ige_T[mclr_counts_family.columns]\n",
    "\n",
    "# Concatenate the data\n",
    "all_counts_ige = pd.concat([mclr_counts_family, ige_T])\n",
    "\n",
    "all_counts_ige.T.to_csv('data/all_counts_ige.csv', index=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "44c81a44-de27-4be9-a220-3bf4a6b640d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filtered_taxa = taxa[taxa['family'].isin(df_unique.index)]\n",
    "\n",
    "# Remove duplicate entries based on the 'family' column in filtered_taxa\n",
    "filtered_taxa = filtered_taxa.drop_duplicates(subset='family')\n",
    "\n",
    "# Create an empty DataFrame with the same index as df_unique\n",
    "label_df = pd.DataFrame(index=df_unique.index)\n",
    "\n",
    "# Map the 'phylum' from filtered_taxa based on the 'family' to the new DataFrame\n",
    "label_df['phylum'] = filtered_taxa.set_index('family')['phylum']\n",
    "\n",
    "# Reindex to ensure all indices of df_unique are present, including missing values\n",
    "label_df = label_df.reindex(all_counts_ige.index)\n",
    "\n",
    "label_df.index = label_df.index.str.replace('.', '_', regex=False)\n",
    "\n",
    "label_df = label_df.fillna(\"p__ige\")\n",
    "\n",
    "label_df.to_csv('data/phylum_labels.csv', index=True, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ea2d04-9584-4faa-a99e-f438d1929324",
   "metadata": {},
   "source": [
    "#### We use R package NetCoMi for the visualization (code is available in RMarkdown)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
